# ğŸ’» Explication DÃ©taillÃ©e du Code - ModÃ¨le IA

**Date** : 19 janvier 2026  
**Fichiers** : `model.py`, `train_model.py`, `main.py`  
**Langage** : Python 3.x avec scikit-learn

---

## ğŸ“š Table des MatiÃ¨res

1. [Structure du Projet](#structure-du-projet)
2. [model.py - Classe AsthmaPredictor](#modelpy---classe-asthmapredictor)
3. [train_model.py - EntraÃ®nement](#train_modelpy---entraÃ®nement)
4. [main.py - API Flask](#mainpy---api-flask)
5. [Flux de DonnÃ©es Complet](#flux-de-donnÃ©es-complet)

---

## ğŸ“ Structure du Projet

```
asthme-ia/
â”œâ”€â”€ model.py                 # ğŸ§  Classe du modÃ¨le Random Forest
â”œâ”€â”€ train_model.py           # ğŸ‹ï¸ Script d'entraÃ®nement
â”œâ”€â”€ main.py                  # ğŸŒ API Flask
â”œâ”€â”€ requirements.txt         # ğŸ“¦ DÃ©pendances Python
â”œâ”€â”€ data/
â”‚   â””â”€â”€ asthma_detection_final.csv  # ğŸ“Š Dataset (3663 patients)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ asthma_model.pkl     # ğŸ’¾ ModÃ¨le entraÃ®nÃ© sauvegardÃ©
â””â”€â”€ docs/
    â””â”€â”€ *.md                  # ğŸ“– Documentation
```

---

## ğŸ§  model.py - Classe AsthmaPredictor

### Vue d'Ensemble

```python
"""
Module de prÃ©diction du risque d'asthme avec Random Forest
"""
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import os
```

**Imports expliquÃ©s** :
- `pandas` : Manipulation des donnÃ©es tabulaires (CSV)
- `numpy` : Calculs numÃ©riques
- `RandomForestClassifier` : Algorithme de machine learning
- `train_test_split` : Diviser donnÃ©es en train/test
- `cross_val_score` : Validation croisÃ©e
- `StratifiedKFold` : Cross-validation stratifiÃ©e (maintient proportions des classes)
- `classification_report`, `confusion_matrix`, `accuracy_score` : MÃ©triques de performance
- `joblib` : Sauvegarder/charger le modÃ¨le
- `os` : Manipulation de fichiers/dossiers

---

### 1. Initialisation de la Classe

```python
class AsthmaPredictor:
    """Classe pour la prÃ©diction du risque d'asthme"""
    
    def __init__(self, model_path='models/asthma_model.pkl', high_risk_threshold=0.65):
        """
        Initialise le prÃ©dicteur
        
        Args:
            model_path: Chemin vers le modÃ¨le sauvegardÃ©
            high_risk_threshold: Seuil de probabilitÃ© pour dÃ©clencher alerte critique (0.6-0.7)
        """
        self.model_path = model_path
        self.model = None  # Sera rempli aprÃ¨s entraÃ®nement ou chargement
        self.feature_names = None  # Liste des 18 features
        self.high_risk_threshold = high_risk_threshold  # Seuil mÃ©dical pour classe critique
        self.min_feature_importance = 0.001  # Filtrer features < 0.1% d'importance
        self.risk_labels = {
            1: 'Faible',
            2: 'ModÃ©rÃ©',
            3: 'Ã‰levÃ©'
        }
```

**Explication ligne par ligne** :

```python
self.model_path = model_path
```
- Stocke le chemin oÃ¹ sauvegarder/charger le modÃ¨le
- Par dÃ©faut : `models/asthma_model.pkl`

```python
self.model = None
```
- Contiendra le modÃ¨le RandomForestClassifier une fois entraÃ®nÃ©
- `None` au dÃ©but (pas encore entraÃ®nÃ©)

```python
self.feature_names = None
```
- Liste des noms des 18 features dans l'ordre exact
- Exemple : `['Tiredness', 'Dry-Cough', ..., 'RespiratoryRate']`
- Important pour rÃ©ordonner les donnÃ©es lors de la prÃ©diction

```python
self.high_risk_threshold = high_risk_threshold  # 0.65 par dÃ©faut
```
- **Seuil critique mÃ©dical** : Si probabilitÃ©(Ã‰levÃ©) â‰¥ 65%, forcer alerte
- PrioritÃ© Ã  la sÃ©curitÃ© mÃ©dicale (Ã©viter faux nÃ©gatifs)

```python
self.min_feature_importance = 0.001
```
- Features avec importance < 0.1% sont considÃ©rÃ©es comme bruit
- Permet d'identifier les features Ã  potentiellement supprimer

```python
self.risk_labels = {1: 'Faible', 2: 'ModÃ©rÃ©', 3: 'Ã‰levÃ©'}
```
- Mapping entre les classes numÃ©riques et les labels texte
- Facilite l'affichage pour l'utilisateur

---

### 2. Nettoyage des DonnÃ©es

```python
def _clean_sensor_data(self, df):
    """
    Nettoie les valeurs aberrantes des capteurs
    
    Args:
        df: DataFrame avec les donnÃ©es
        
    Returns:
        df: DataFrame nettoyÃ©
    """
    df_clean = df.copy()
    
    # Nettoyer les capteurs environnementaux
    if 'Temperature' in df_clean.columns:
        # TempÃ©rature corporelle normale: 35-42Â°C
        df_clean.loc[df_clean['Temperature'] < 35, 'Temperature'] = 36.5
        df_clean.loc[df_clean['Temperature'] > 42, 'Temperature'] = 37.0
```

**Explication** :

```python
df_clean = df.copy()
```
- CrÃ©e une copie du DataFrame pour ne pas modifier l'original
- Bonne pratique en Python

```python
if 'Temperature' in df_clean.columns:
```
- VÃ©rifie si la colonne 'Temperature' existe
- Permet de gÃ©rer diffÃ©rents formats de datasets

```python
df_clean.loc[df_clean['Temperature'] < 35, 'Temperature'] = 36.5
```
- **SÃ©lection conditionnelle** :
  - `df_clean['Temperature'] < 35` : BoolÃ©en True/False pour chaque ligne
  - `df_clean.loc[condition, 'Temperature']` : SÃ©lectionne les lignes oÃ¹ condition = True
  - `= 36.5` : Remplace par la valeur normale

**Logique mÃ©dicale** :
- TempÃ©rature < 35Â°C â†’ **Hypothermie** (probable erreur capteur) â†’ Remplacer par 36.5Â°C (normal)
- TempÃ©rature > 42Â°C â†’ **Hyperthermie dangereuse** (probable erreur capteur) â†’ Remplacer par 37.0Â°C (limite)

**MÃªme logique pour les autres capteurs** :

```python
if 'Humidity' in df_clean.columns:
    # HumiditÃ©: 0-100%
    df_clean.loc[df_clean['Humidity'] < 0, 'Humidity'] = 30
    df_clean.loc[df_clean['Humidity'] > 100, 'Humidity'] = 70
```
- HumiditÃ© < 0% ou > 100% â†’ Physiquement impossible â†’ Corriger

```python
if 'PM25' in df_clean.columns:
    # PM2.5: 0-500 Âµg/mÂ³ (valeurs rÃ©alistes)
    df_clean.loc[df_clean['PM25'] < 0, 'PM25'] = 0
    df_clean.loc[df_clean['PM25'] > 500, 'PM25'] = 500
```
- PM2.5 < 0 â†’ Impossible â†’ 0
- PM2.5 > 500 â†’ ExtrÃªmement rare â†’ Limiter Ã  500

```python
if 'RespiratoryRate' in df_clean.columns:
    # FrÃ©quence respiratoire: 10-40 respirations/min
    df_clean.loc[df_clean['RespiratoryRate'] < 10, 'RespiratoryRate'] = 16
    df_clean.loc[df_clean['RespiratoryRate'] > 40, 'RespiratoryRate'] = 25
```
- FrÃ©quence < 10 â†’ Anormalement bas â†’ 16 (normal)
- FrÃ©quence > 40 â†’ Hyperventilation extrÃªme â†’ 25 (Ã©levÃ©)

---

### 3. Chargement des DonnÃ©es

```python
def load_data(self, csv_path='data/asthma_detection_with_sensors.csv'):
    """
    Charge et prÃ©pare les donnÃ©es avec nettoyage des valeurs aberrantes
    
    Args:
        csv_path: Chemin vers le fichier CSV
        
    Returns:
        X, y: Features et target
    """
    # Charger le dataset
    df = pd.read_csv(csv_path)
```

**Explication** :

```python
df = pd.read_csv(csv_path)
```
- Lit le fichier CSV et crÃ©e un DataFrame pandas
- Structure : 3663 lignes (patients) Ã— 19 colonnes (18 features + 1 target)

```python
# Nettoyer les valeurs aberrantes des capteurs
df = self._clean_sensor_data(df)
```
- Appelle la mÃ©thode de nettoyage dÃ©finie prÃ©cÃ©demment
- Corrige les valeurs impossibles/aberrantes

```python
# SÃ©parer features et target
X = df.drop('Asthma', axis=1)
y = df['Asthma']
```
- `X` : **Features** (variables prÃ©dictives) - 18 colonnes
  ```
  [Tiredness, Dry-Cough, ..., RespiratoryRate]
  ```
- `y` : **Target** (variable Ã  prÃ©dire) - 1 colonne
  ```
  [1, 2, ou 3]  (Faible, ModÃ©rÃ©, Ã‰levÃ©)
  ```
- `axis=1` : Supprimer une colonne (pas une ligne)

```python
# Sauvegarder les noms des features
self.feature_names = X.columns.tolist()
```
- Stocke les noms des colonnes dans l'ordre exact
- **Crucial** : Le modÃ¨le doit recevoir les features dans le mÃªme ordre

```python
print(f"Features chargÃ©es: {len(self.feature_names)}")
if 'Temperature' in self.feature_names:
    print("âœ“ DonnÃ©es de capteurs dÃ©tectÃ©es (TempÃ©rature, HumiditÃ©, PM2.5, AQI, FrÃ©quence cardiaque)")
print("âœ“ Nettoyage des valeurs aberrantes effectuÃ©")
```
- Affichage d'informations pour l'utilisateur
- `f"..."` : f-string pour formater le texte avec des variables

```python
return X, y
```
- Retourne les features et le target pour l'entraÃ®nement

---

### 4. EntraÃ®nement du ModÃ¨le

```python
def train(self, X, y, test_size=0.2, random_state=42):
    """
    EntraÃ®ne le modÃ¨le Random Forest
    
    Args:
        X: Features
        y: Target
        test_size: Proportion du test set
        random_state: Seed pour reproductibilitÃ©
        
    Returns:
        metrics: Dictionnaire avec les mÃ©triques de performance
    """
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
```

**Explication du split** :

```python
train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
```
- `X, y` : DonnÃ©es Ã  diviser
- `test_size=0.2` : **20% pour test, 80% pour entraÃ®nement**
  ```
  3663 patients total
  â”œâ”€â”€ Train: 2930 patients (80%)
  â””â”€â”€ Test:   733 patients (20%)
  ```
- `random_state=42` : **Seed alÃ©atoire** pour reproductibilitÃ©
  - Toujours la mÃªme division Ã  chaque exÃ©cution
- `stratify=y` : **Maintient les proportions des classes**
  ```
  Dataset original: 33% Faible, 33% ModÃ©rÃ©, 33% Ã‰levÃ©
  Train set:        33% Faible, 33% ModÃ©rÃ©, 33% Ã‰levÃ©  âœ…
  Test set:         33% Faible, 33% ModÃ©rÃ©, 33% Ã‰levÃ©  âœ…
  ```

**Retour** : 4 objets
```python
X_train  # Features d'entraÃ®nement (2930 Ã— 18)
X_test   # Features de test (733 Ã— 18)
y_train  # Target d'entraÃ®nement (2930)
y_test   # Target de test (733)
```

---

#### Configuration du Random Forest

```python
# CrÃ©er et entraÃ®ner le modÃ¨le Random Forest avec hyperparamÃ¨tres optimisÃ©s
# Utilisation d'un nombre impair d'arbres pour Ã©viter les Ã©galitÃ©s
self.model = RandomForestClassifier(
    n_estimators=151,           # Nombre d'arbres (impair!)
    max_depth=12,              # Profondeur maximale
    min_samples_split=5,       # Min Ã©chantillons pour split
    min_samples_leaf=1,        # Min Ã©chantillons par feuille
    random_state=random_state,
    class_weight={1: 1.0, 2: 1.0, 3: 1.5},  # Poids ajustÃ© pour classe critique
    n_jobs=-1                  # Utilise tous les CPU
)
```

**Chaque paramÃ¨tre expliquÃ©** :

**n_estimators=151**
```python
# Nombre d'arbres de dÃ©cision dans la forÃªt
# 151 au lieu de 150 â†’ nombre impair â†’ Ã©vite Ã©galitÃ©s dans le vote
# Exemple de vote:
#   150 arbres: 75 vs 75 = Ã©galitÃ© possible âŒ
#   151 arbres: 76 vs 75 = toujours un gagnant âœ…
```

**max_depth=12**
```python
# Profondeur maximale de chaque arbre (12 niveaux)
# Plus profond = capture patterns complexes
# Trop profond = surapprentissage
# 12 = bon compromis pour notre dataset
```

**min_samples_split=5**
```python
# Minimum 5 Ã©chantillons pour crÃ©er une nouvelle branche
# Si nÅ“ud < 5 patients â†’ ne pas diviser (devient feuille)
# Ã‰vite de crÃ©er des branches sur trop peu de donnÃ©es (bruit)
```

**min_samples_leaf=1**
```python
# Minimum 1 Ã©chantillon dans chaque feuille
# Plus flexible que 2
# Permet au modÃ¨le d'apprendre des cas particuliers
```

**class_weight={1: 1.0, 2: 1.0, 3: 1.5}**
```python
# Poids de chaque classe lors de l'entraÃ®nement
# Classe 1 (Faible): poids normal (1.0)
# Classe 2 (ModÃ©rÃ©): poids normal (1.0)
# Classe 3 (Ã‰levÃ©):  poids augmentÃ© (1.5) âš¡
# 
# Impact: Le modÃ¨le fait plus attention aux erreurs sur classe 3
# â†’ RÃ©duit les faux nÃ©gatifs (ne pas rater un cas grave)
```

**n_jobs=-1**
```python
# Nombre de CPU Ã  utiliser
# -1 = TOUS les CPU disponibles
# ParallÃ©lisation = entraÃ®nement beaucoup plus rapide
# 
# Exemple avec 8 CPU:
#   n_jobs=1  â†’ 8 minutes
#   n_jobs=-1 â†’ 1 minute
```

---

#### EntraÃ®nement

```python
print("EntraÃ®nement du modÃ¨le Random Forest optimisÃ©...")
print(f"  â€¢ n_estimators: 151 (nombre impair)")
print(f"  â€¢ max_depth: 12 (patterns complexes)")
print(f"  â€¢ min_samples_leaf: 1 (flexibilitÃ©)")
print(f"  â€¢ class_weight: {{1:1.0, 2:1.0, 3:1.5}} (prioritÃ© classe critique)")
print(f"  â€¢ Seuil alerte critique: {self.high_risk_threshold:.2f}")

self.model.fit(X_train, y_train)
```

**`model.fit(X_train, y_train)`** :
- **C'est ici que la magie opÃ¨re !**
- Le modÃ¨le construit 151 arbres de dÃ©cision
- Processus pour chaque arbre :
  1. **Bootstrap** : Tirer ~2930 Ã©chantillons alÃ©atoires avec remise
  2. **Construire l'arbre** :
     - Ã€ chaque nÅ“ud : sÃ©lectionner âˆš18 â‰ˆ 4 features alÃ©atoires
     - Choisir la meilleure feature pour diviser
     - CrÃ©er branches gauche/droite
     - RÃ©pÃ©ter jusqu'Ã  max_depth=12
  3. **Stocker l'arbre**

---

#### Ã‰valuation

```python
# PrÃ©dictions sur le test set
y_pred = self.model.predict(X_test)
```

**`predict(X_test)`** :
- Fait voter les 151 arbres pour chaque patient du test set
- Retourne la classe majoritaire (1, 2, ou 3)

```python
# MÃ©triques
accuracy = accuracy_score(y_test, y_pred)
```

**accuracy_score** :
```python
# Calcule : nombre de prÃ©dictions correctes / total
# Exemple:
#   y_test = [1, 2, 3, 1, 2]  (vraies valeurs)
#   y_pred = [1, 2, 2, 1, 2]  (prÃ©dictions)
#   correct: 4/5 = 80% accuracy
```

```python
# Cross-validation amÃ©liorÃ©e avec StratifiedKFold (10 folds)
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)
cv_scores = cross_val_score(self.model, X_train, y_train, cv=skf)
```

**StratifiedKFold** :
```python
# Divise les donnÃ©es en 10 parties Ã©gales
# Pour chaque fold (1 Ã  10):
#   - Utiliser 1 fold pour test
#   - Utiliser 9 folds pour entraÃ®nement
#   - Calculer l'accuracy
# 
# RÃ©sultat: [0.976, 0.983, 0.968, ..., 0.970]
# Moyenne: 97.17%
# Ã‰cart-type: 0.85%
```

**Avantages** :
- Plus robuste qu'un simple train/test split
- Chaque Ã©chantillon est testÃ© exactement 1 fois
- Mesure la capacitÃ© de gÃ©nÃ©ralisation

---

#### Feature Importance

```python
# Importance des features
feature_importance = pd.DataFrame({
    'feature': self.feature_names,
    'importance': self.model.feature_importances_
}).sort_values('importance', ascending=False)
```

**`self.model.feature_importances_`** :
- Array de 18 valeurs (une par feature)
- Somme = 1.0 (100%)
- Exemple : `[0.291, 0.250, 0.084, ..., 0.003]`

**Calcul de l'importance** :
```python
# Pour chaque feature:
#   1. Calculer la rÃ©duction d'impuretÃ© quand on l'utilise pour diviser
#   2. Sommer sur tous les arbres (151)
#   3. Normaliser (diviser par somme totale)
# 
# RÃ©sultat:
#   RespiratoryRate: 29.1%  â† Feature la plus utile
#   PM25: 25.0%
#   ...
#   Gender_Female: 0.3%  â† Feature la moins utile
```

```python
# Identifier les features nÃ©gligeables (< 0.1% d'importance)
low_importance_features = feature_importance[feature_importance['importance'] < self.min_feature_importance]
important_features = feature_importance[feature_importance['importance'] >= self.min_feature_importance]
```

- Filtre les features trÃ¨s peu importantes
- Permet d'identifier le "bruit" dans les donnÃ©es

---

#### Affichage des RÃ©sultats

```python
print(f"\n{'='*50}")
print(f"RÃ‰SULTATS DE L'ENTRAÃNEMENT")
print(f"{'='*50}")
print(f"Accuracy sur test set: {accuracy:.4f}")
print(f"Cross-validation score (10-fold): {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
```

**Format des affichages** :
- `:.4f` : 4 dÃ©cimales (0.9604)
- `cv_scores.mean()` : Moyenne des 10 scores
- `cv_scores.std()` : Ã‰cart-type (variance)

```python
if len(low_importance_features) > 0:
    print(f"\nâš ï¸ {len(low_importance_features)} feature(s) nÃ©gligeable(s) dÃ©tectÃ©e(s) (< {self.min_feature_importance*100:.1f}%):")
    for feat in low_importance_features['feature'].tolist():
        print(f"  - {feat}")
    print("  Conseil: ConsidÃ©rer leur suppression pour rÃ©duire le bruit")
```

- Avertit si certaines features sont inutiles
- Suggestion d'amÃ©lioration

```python
print(f"\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=[self.risk_labels.get(i, str(i)) for i in sorted(y_test.unique())]))
```

**classification_report** :
```
              precision    recall  f1-score   support

      Faible       0.97      0.95      0.96       244
      ModÃ©rÃ©       0.93      0.96      0.95       244
       Ã‰levÃ©       0.98      0.96      0.97       245
```

- **Precision** : Parmi les prÃ©dictions "Ã‰levÃ©", combien sont vraiment Ã‰levÃ© ?
- **Recall** : Parmi les vrais "Ã‰levÃ©", combien sont dÃ©tectÃ©s ?
- **F1-score** : Moyenne harmonique de precision et recall
- **Support** : Nombre d'Ã©chantillons de cette classe

```python
print(f"\nMatrice de confusion:")
print(confusion_matrix(y_test, y_pred))
```

**Matrice de confusion** :
```
[[233  11   0]    â† Faible: 233 OK, 11 erreurs
 [  5 235   4]    â† ModÃ©rÃ©: 235 OK, 9 erreurs
 [  2   7 236]]   â† Ã‰levÃ©: 236 OK, 9 erreurs
```

---

### 5. Sauvegarde du ModÃ¨le

```python
def save_model(self):
    """Sauvegarde le modÃ¨le entraÃ®nÃ©"""
    if self.model is None:
        raise ValueError("Le modÃ¨le n'a pas encore Ã©tÃ© entraÃ®nÃ©")
    
    # CrÃ©er le dossier models s'il n'existe pas
    os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
    
    # Sauvegarder le modÃ¨le et les feature names
    model_data = {
        'model': self.model,
        'feature_names': self.feature_names,
        'risk_labels': self.risk_labels
    }
    
    joblib.dump(model_data, self.model_path)
    print(f"\nModÃ¨le sauvegardÃ© dans: {self.model_path}")
```

**Explication** :

```python
os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
```
- `os.path.dirname('models/asthma_model.pkl')` â†’ `'models'`
- `os.makedirs('models', exist_ok=True)` â†’ CrÃ©e le dossier si n'existe pas
- `exist_ok=True` â†’ Pas d'erreur si le dossier existe dÃ©jÃ 

```python
model_data = {
    'model': self.model,
    'feature_names': self.feature_names,
    'risk_labels': self.risk_labels
}
```
- Dictionnaire contenant TOUT ce qu'on a besoin pour faire des prÃ©dictions
- Pas juste le modÃ¨le, mais aussi les mÃ©tadonnÃ©es

```python
joblib.dump(model_data, self.model_path)
```
- `joblib` : Librairie optimisÃ©e pour sauvegarder des objets scikit-learn
- CrÃ©e un fichier `.pkl` (pickle) de ~3-6 MB

---

### 6. Chargement du ModÃ¨le

```python
def load_model(self):
    """Charge le modÃ¨le sauvegardÃ©"""
    if not os.path.exists(self.model_path):
        raise FileNotFoundError(f"ModÃ¨le non trouvÃ©: {self.model_path}")
    
    model_data = joblib.load(self.model_path)
    self.model = model_data['model']
    self.feature_names = model_data['feature_names']
    self.risk_labels = model_data['risk_labels']
    
    print(f"ModÃ¨le chargÃ© depuis: {self.model_path}")
```

**Explication** :

```python
if not os.path.exists(self.model_path):
    raise FileNotFoundError(...)
```
- VÃ©rifie si le fichier existe avant de charger
- `raise` : LÃ¨ve une erreur si le fichier n'existe pas

```python
model_data = joblib.load(self.model_path)
```
- Charge le fichier `.pkl`
- Retourne le dictionnaire sauvegardÃ© prÃ©cÃ©demment

```python
self.model = model_data['model']
self.feature_names = model_data['feature_names']
self.risk_labels = model_data['risk_labels']
```
- Extrait les Ã©lÃ©ments du dictionnaire
- Restaure l'Ã©tat complet du prÃ©dicteur

---

### 7. PrÃ©diction (â¤ï¸ COEUR DU SYSTÃˆME)

```python
def predict(self, features):
    """
    PrÃ©dit le risque d'asthme
    
    Args:
        features: Dictionnaire ou DataFrame avec les features
        
    Returns:
        prediction: Dictionnaire avec le risque et les recommandations
    """
    if self.model is None:
        try:
            self.load_model()
        except FileNotFoundError:
            raise ValueError("Le modÃ¨le doit Ãªtre entraÃ®nÃ© ou chargÃ© avant de faire des prÃ©dictions")
```

**Auto-chargement** :
- Si le modÃ¨le n'est pas en mÃ©moire, essaie de le charger automatiquement
- Pratique pour l'API Flask

```python
# Convertir en DataFrame si nÃ©cessaire
if isinstance(features, dict):
    features_df = pd.DataFrame([features])
else:
    features_df = features
```

**Gestion de types** :
```python
# features peut Ãªtre:
# 1. Un dictionnaire: {'Tiredness': 1, 'Dry-Cough': 1, ...}
# 2. Un DataFrame: pd.DataFrame avec les colonnes

# On convertit tout en DataFrame pour uniformiser
```

```python
# VÃ©rifier que toutes les features sont prÃ©sentes
missing_features = set(self.feature_names) - set(features_df.columns)
if missing_features:
    raise ValueError(f"Features manquantes: {missing_features}")
```

**Validation** :
```python
# self.feature_names = ['Tiredness', 'Dry-Cough', ..., 'RespiratoryRate']
# features_df.columns = ['Tiredness', 'PM25', ...]  â† Il manque des colonnes!

# set(A) - set(B) = Ã©lÃ©ments dans A mais pas dans B
# Si missing_features non vide â†’ erreur
```

```python
# RÃ©organiser les colonnes dans le bon ordre
features_df = features_df[self.feature_names]
```

**CRUCIAL** :
- Le modÃ¨le attend les features dans un ordre prÃ©cis
- Exemple :
  ```python
  # EntraÃ®nement: ['Tiredness', 'Dry-Cough', 'PM25']
  # PrÃ©diction:   ['PM25', 'Tiredness', 'Dry-Cough']  â† Mauvais ordre!
  # 
  # features_df[self.feature_names] â†’ rÃ©ordonne correctement
  ```

---

#### Application du Seuil Critique (âš¡ INNOVATION)

```python
# PrÃ©diction avec probabilitÃ©s
risk_probabilities = self.model.predict_proba(features_df)[0]
risk_level_default = int(self.model.predict(features_df)[0])
```

**predict_proba** :
```python
# Retourne les probabilitÃ©s pour chaque classe
# Exemple: [[0.265, 0.258, 0.477]]
#            â†‘      â†‘      â†‘
#         Faible ModÃ©rÃ© Ã‰levÃ©
# 
# [0] â†’ Premier (et seul) patient
# RÃ©sultat: [0.265, 0.258, 0.477]
```

**predict** :
```python
# Retourne la classe majoritaire (vote des arbres)
# Exemple: [3]  (classe Ã‰levÃ©)
# 
# int(...) â†’ Convertir en entier Python
```

```python
# Convertir les probabilitÃ©s en dict
prob_dict = {
    int(cls): float(prob) 
    for cls, prob in zip(self.model.classes_, risk_probabilities)
}
```

**Comprehension de dictionnaire** :
```python
# self.model.classes_ = [1, 2, 3]
# risk_probabilities  = [0.265, 0.258, 0.477]
# 
# zip() â†’ [(1, 0.265), (2, 0.258), (3, 0.477)]
# 
# RÃ©sultat: {1: 0.265, 2: 0.258, 3: 0.477}
```

```python
# Appliquer le seuil mÃ©dical pour la classe critique (3 = Ã‰levÃ©)
# Si probabilitÃ© de classe 3 >= seuil critique, forcer l'alerte
risk_level = risk_level_default
if 3 in prob_dict and prob_dict[3] >= self.high_risk_threshold:
    risk_level = 3  # Forcer alerte critique pour sÃ©curitÃ© mÃ©dicale
    print(f"âš ï¸ ALERTE CRITIQUE: ProbabilitÃ© classe Ã‰levÃ© = {prob_dict[3]:.2%} >= seuil {self.high_risk_threshold:.2%}")
```

**Logique du seuil** :
```python
# ScÃ©nario 1: ProbabilitÃ©s [35%, 33%, 32%]
#   - Vote majoritaire: Faible (35%)
#   - prob_dict[3] = 32% < 65%
#   - RÃ©sultat: Faible (normal)

# ScÃ©nario 2: ProbabilitÃ©s [20%, 15%, 65%]
#   - Vote majoritaire: Ã‰levÃ© (65%)
#   - prob_dict[3] = 65% >= 65%
#   - RÃ©sultat: Ã‰levÃ© (alerte dÃ©clenchÃ©e)
#   - Affiche: "âš ï¸ ALERTE CRITIQUE..."

# ScÃ©nario 3: ProbabilitÃ©s [40%, 40%, 20%]
#   - Vote majoritaire: Faible ou ModÃ©rÃ©
#   - prob_dict[3] = 20% < 65%
#   - RÃ©sultat: Vote majoritaire (normal)

# L'intÃ©rÃªt: MÃªme si vote majoritaire â‰  Ã‰levÃ©,
# on dÃ©clenche l'alerte si risque Ã‰levÃ© â‰¥ 65%
```

```python
# Calculer un score global (probabilitÃ© de la classe prÃ©dite)
risk_score = float(risk_probabilities[list(self.model.classes_).index(risk_level)])
```

**Extraction du score** :
```python
# risk_level = 3 (Ã‰levÃ©)
# self.model.classes_ = [1, 2, 3]
# list(...) = [1, 2, 3]
# .index(3) = 2  (position de 3 dans la liste)
# risk_probabilities[2] = 0.477
# 
# risk_score = 0.477 (47.7%)
```

```python
# GÃ©nÃ©rer des recommandations basÃ©es sur le niveau de risque
recommendations = self._generate_recommendations(risk_level, features_df.iloc[0].to_dict())
```

- Appelle une mÃ©thode pour gÃ©nÃ©rer des recommandations personnalisÃ©es
- `.iloc[0]` : Premier patient du DataFrame
- `.to_dict()` : Convertir en dictionnaire

```python
return {
    'risk_level': risk_level,
    'risk_label': self.risk_labels.get(risk_level, 'Inconnu'),
    'risk_score': risk_score,
    'probabilities': prob_dict,
    'recommendations': recommendations
}
```

**Retour formatÃ©** :
```python
{
    'risk_level': 3,
    'risk_label': 'Ã‰levÃ©',
    'risk_score': 0.477,
    'probabilities': {1: 0.265, 2: 0.258, 3: 0.477},
    'recommendations': [
        "âš ï¸ Consultez IMMÃ‰DIATEMENT un mÃ©decin",
        "Ã‰vitez tout effort physique",
        ...
    ]
}
```

---

### 8. GÃ©nÃ©ration de Recommandations

```python
def _generate_recommendations(self, risk_level, features):
    """
    GÃ©nÃ¨re des recommandations personnalisÃ©es
    
    Args:
        risk_level: Niveau de risque prÃ©dit
        features: Dictionnaire des features du patient
        
    Returns:
        recommendations: Liste de recommandations
    """
    recommendations = []
    
    # Recommandations basÃ©es sur le niveau de risque
    if risk_level == 3:  # Risque Ã©levÃ©
        recommendations.append("âš ï¸ Consultez IMMÃ‰DIATEMENT un mÃ©decin ou pneumologue")
        recommendations.append("Ã‰vitez tout effort physique intense")
        recommendations.append("Gardez votre inhalateur Ã  portÃ©e de main si vous en avez un")
    elif risk_level == 2:  # Risque modÃ©rÃ©
        recommendations.append("Consultez un mÃ©decin dans les prochains jours")
        recommendations.append("Surveillez attentivement vos symptÃ´mes")
        recommendations.append("Ã‰vitez les allergÃ¨nes et la pollution")
    else:  # Risque faible
        recommendations.append("Maintenez une bonne hygiÃ¨ne de vie")
        recommendations.append("Surveillez l'apparition de nouveaux symptÃ´mes")
```

**Logique conditionnelle** :
- Recommandations **gÃ©nÃ©rales** basÃ©es sur le niveau de risque
- Structure if/elif/else pour les 3 cas

```python
# Recommandations basÃ©es sur les symptÃ´mes
if features.get('Difficulty-in-Breathing', 0) == 1:
    recommendations.append("Respirez lentement et profondÃ©ment")
    recommendations.append("Asseyez-vous dans une position confortable")

if features.get('Dry-Cough', 0) == 1:
    recommendations.append("Hydratez-vous rÃ©guliÃ¨rement")
    recommendations.append("Ã‰vitez les irritants (fumÃ©e, poussiÃ¨re)")
```

**`features.get('key', default)`** :
```python
# RÃ©cupÃ¨re la valeur de la clÃ©, sinon retourne default
# features = {'Difficulty-in-Breathing': 1, 'Dry-Cough': 0}
# 
# features.get('Difficulty-in-Breathing', 0) â†’ 1
# features.get('Runny-Nose', 0) â†’ 0 (clÃ© inexistante, retourne default)
```

```python
# Recommandations basÃ©es sur les capteurs environnementaux
pm25 = features.get('PM25', None)
if pm25 is not None:
    if pm25 > 55:
        recommendations.append("ğŸŒ«ï¸ QualitÃ© de l'air trÃ¨s mauvaise - Restez Ã  l'intÃ©rieur")
    elif pm25 > 35:
        recommendations.append("ğŸŒ«ï¸ QualitÃ© de l'air mauvaise - Limitez les activitÃ©s extÃ©rieures")
```

**Seuils PM2.5** :
```
0-12:   Bonne qualitÃ© (vert)
13-35:  Moyenne (jaune)
36-55:  Mauvaise (orange) â†’ "Limitez activitÃ©s"
56+:    TrÃ¨s mauvaise (rouge) â†’ "Restez Ã  l'intÃ©rieur"
```

```python
humidity = features.get('Humidity', None)
if humidity is not None:
    if humidity > 70:
        recommendations.append("ğŸ’§ HumiditÃ© Ã©levÃ©e - Utilisez un dÃ©shumidificateur")
    elif humidity < 30:
        recommendations.append("ğŸ’§ Air trop sec - Utilisez un humidificateur")
```

**HumiditÃ© optimale** : 30-70%
- Trop Ã©levÃ©e (>70%) : Favorise moisissures, acariens
- Trop basse (<30%) : Irrite voies respiratoires

```python
# Retourner les recommandations les plus pertinentes (max 8)
return recommendations[:8]
```

- `[:8]` : Prend les 8 premiers Ã©lÃ©ments de la liste
- Ã‰vite une liste trop longue pour l'utilisateur

---

## ğŸ‹ï¸ train_model.py - Script d'EntraÃ®nement

### Vue d'ensemble

```python
"""
Script d'entraÃ®nement du modÃ¨le Random Forest pour la prÃ©diction d'asthme
"""
from model import AsthmaPredictor
import os

def main():
    """Fonction principale d'entraÃ®nement"""
    
    print("="*60)
    print("ENTRAÃNEMENT DU MODÃˆLE DE PRÃ‰DICTION D'ASTHME")
    print("Algorithme: Random Forest Classifier")
    print("="*60)
```

**Imports** :
- `from model import AsthmaPredictor` : Importe la classe du fichier `model.py`
- `import os` : Pour crÃ©er des dossiers

```python
# CrÃ©er le dossier models s'il n'existe pas
os.makedirs('models', exist_ok=True)
```

- PrÃ©pare le dossier de sauvegarde

```python
# Initialiser le prÃ©dicteur
predictor = AsthmaPredictor(model_path='models/asthma_model.pkl')
```

- CrÃ©e une instance de la classe
- `predictor` : Objet qu'on va utiliser pour entraÃ®ner

```python
# Charger les donnÃ©es
print("\nChargement des donnÃ©es...")
X, y = predictor.load_data('data/asthma_detection_final.csv')
print(f"Dataset chargÃ©: {X.shape[0]} Ã©chantillons, {X.shape[1]} features")
```

- `X.shape` : Tuple `(lignes, colonnes)`
- `X.shape[0]` : Nombre de lignes (3663 patients)
- `X.shape[1]` : Nombre de colonnes (18 features)

```python
print(f"Distribution des classes:")
print(y.value_counts().sort_index())
```

**value_counts()** :
```python
# Compte le nombre de chaque valeur unique
# y = [1, 2, 3, 1, 2, 3, ...]
# 
# RÃ©sultat:
# 1    1221  (Faible)
# 2    1221  (ModÃ©rÃ©)
# 3    1221  (Ã‰levÃ©)
```

```python
# EntraÃ®ner le modÃ¨le
print("\n" + "="*60)
metrics = predictor.train(X, y, test_size=0.2, random_state=42)
```

- Appelle la mÃ©thode `train()` vue prÃ©cÃ©demment
- `metrics` : Dictionnaire avec les rÃ©sultats

```python
# Sauvegarder le modÃ¨le
print("\n" + "="*60)
predictor.save_model()
```

- Sauvegarde dans `models/asthma_model.pkl`

---

### Test de PrÃ©diction

```python
# Test de prÃ©diction avec un exemple
print("\n" + "="*60)
print("TEST DE PRÃ‰DICTION")
print("="*60)

# Exemple: Patient avec plusieurs symptÃ´mes et donnÃ©es de capteurs
test_example = {
    'Tiredness': 1,
    'Dry-Cough': 1,
    'Difficulty-in-Breathing': 1,
    'Sore-Throat': 1,
    'Pains': 0,
    'Nasal-Congestion': 1,
    'Runny-Nose': 0,
    'Age_0-9': 0,
    'Age_10-19': 0,
    'Age_20-24': 1,
    'Age_25-59': 0,
    'Age_60+': 0,
    'Gender_Female': 0,
    'Gender_Male': 1,
    'Humidity': 75.0,
    'Temperature': 24.5,
    'PM25': 45.0,
    'RespiratoryRate': 22.0
}
```

**Structure du dictionnaire** :
- ClÃ© : Nom de la feature
- Valeur : 0 ou 1 (symptÃ´mes), valeur numÃ©rique (capteurs)

```python
result = predictor.predict(test_example)
```

- Appelle la mÃ©thode `predict()` vue prÃ©cÃ©demment
- `result` : Dictionnaire avec le rÃ©sultat

```python
print(f"\nğŸ“Š RÃ‰SULTAT DE LA PRÃ‰DICTION:")
print(f"Niveau de risque: {result['risk_level']} - {result['risk_label']}")
print(f"Score de confiance: {result['risk_score']:.2%}")
```

- `.2%` : Format en pourcentage avec 2 dÃ©cimales (47.90%)

```python
print(f"\nProbabilitÃ©s par classe:")
for cls, prob in sorted(result['probabilities'].items()):
    risk_label = predictor.risk_labels.get(cls, str(cls))
    print(f"  {risk_label}: {prob:.2%}")
```

**Boucle sur dictionnaire** :
```python
# result['probabilities'] = {1: 0.265, 2: 0.258, 3: 0.477}
# sorted(...) â†’ [(1, 0.265), (2, 0.258), (3, 0.477)]
# 
# Pour chaque paire (cls, prob):
#   Afficher: "Faible: 26.50%"
```

---

## ğŸŒ main.py - API Flask

### Configuration

```python
"""
API Flask pour E-SantÃ© 4.0 - PrÃ©diction du risque d'asthme
Backend SIMPLIFIÃ‰ : Uniquement prÃ©dictions ML, pas de base de donnÃ©es
"""
from flask import Flask, jsonify, request
from flask_cors import CORS
from model import AsthmaPredictor

# CrÃ©er l'application Flask
app = Flask(__name__)
CORS(app)
```

**Imports** :
- `Flask` : Framework web
- `jsonify` : Convertir dict Python â†’ JSON
- `request` : AccÃ©der aux donnÃ©es envoyÃ©es par le client
- `CORS` : Autoriser requÃªtes depuis l'app Flutter

```python
# Initialiser le prÃ©dicteur d'asthme avec le modÃ¨le optimisÃ©
# Seuil critique Ã  0.65 (65%) pour meilleure sÃ©curitÃ© mÃ©dicale
predictor = AsthmaPredictor(model_path='models/asthma_model.pkl', high_risk_threshold=0.65)
```

- CrÃ©e une instance GLOBALE du prÃ©dicteur
- Charge automatiquement le modÃ¨le au premier predict

---

### Endpoint /api/predict

```python
@app.route('/api/predict', methods=['POST'])
def predict_asthma_risk():
    """
    PrÃ©dire le risque d'asthme basÃ© sur les donnÃ©es du patient et des capteurs
    
    Format attendu:
    {
        "symptoms": {...},
        "demographics": {...},
        "sensors": {...}
    }
    """
    try:
        data = request.get_json()
```

**`@app.route(...)`** :
- **DÃ©corateur** : Associe une URL Ã  une fonction
- `/api/predict` : URL de l'endpoint
- `methods=['POST']` : Accepte seulement les requÃªtes POST

**`request.get_json()`** :
- Lit le corps de la requÃªte HTTP
- Parse le JSON â†’ dictionnaire Python

```python
# VÃ©rifier les sections requises
required_sections = ['symptoms', 'demographics', 'sensors']
missing = [s for s in required_sections if s not in data]
if missing:
    return jsonify({
        'success': False,
        'error': f'Sections manquantes: {missing}'
    }), 400
```

**Validation** :
```python
# List comprehension pour trouver sections manquantes
# missing = ['sensors'] si data = {'symptoms': {...}, 'demographics': {...}}
# 
# 400 = HTTP Bad Request (erreur client)
```

```python
# Construire le dictionnaire de features
features = {}

# Ajouter les symptÃ´mes
for symptom, value in data['symptoms'].items():
    features[symptom] = value

# Ajouter la dÃ©mographie
for demo, value in data['demographics'].items():
    features[demo] = value

# Ajouter les capteurs
for sensor, value in data['sensors'].items():
    features[sensor] = value
```

**Fusion des dictionnaires** :
```python
# data = {
#     'symptoms': {'Tiredness': 1, 'Dry-Cough': 1},
#     'demographics': {'Age_20-24': 1, 'Gender_Male': 1},
#     'sensors': {'PM25': 45.0, 'Humidity': 75.0}
# }
# 
# AprÃ¨s fusion, features = {
#     'Tiredness': 1,
#     'Dry-Cough': 1,
#     'Age_20-24': 1,
#     'Gender_Male': 1,
#     'PM25': 45.0,
#     'Humidity': 75.0,
#     ...
# }
```

```python
# Faire la prÃ©diction
result = predictor.predict(features)

return jsonify({
    'success': True,
    'risk_level': result['risk_level'],
    'risk_label': result['risk_label'],
    'risk_score': result['risk_score'],
    'probabilities': result['probabilities'],
    'recommendations': result['recommendations']
}), 200
```

**jsonify()** :
- Convertit le dictionnaire en JSON
- Ajoute header `Content-Type: application/json`
- `200` = HTTP OK (succÃ¨s)

```python
except ValueError as e:
    return jsonify({
        'success': False,
        'error': f'Feature manquante: {str(e)}'
    }), 400
except Exception as e:
    return jsonify({
        'success': False,
        'error': f'Erreur de prÃ©diction: {str(e)}'
    }), 500
```

**Gestion d'erreurs** :
- `ValueError` : Feature manquante â†’ 400 (erreur client)
- `Exception` : Autre erreur â†’ 500 (erreur serveur)

---

### DÃ©marrage du Serveur

```python
if __name__ == '__main__':
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False
    )
```

**ParamÃ¨tres** :
- `host='0.0.0.0'` : Ã‰coute sur toutes les interfaces rÃ©seau (accessible depuis autres machines)
- `port=5000` : Port HTTP
- `debug=False` : Mode production (pas de debug)

---

## ğŸ”„ Flux de DonnÃ©es Complet

### 1. EntraÃ®nement (train_model.py)

```
ğŸ“Š CSV (3663 patients)
    â†“
[load_data()]
    â†“ Nettoyage
ğŸ“Š X (2930Ã—18), y (2930)
    â†“
[train()]
    â†“ RandomForest(151 arbres)
ğŸ§  ModÃ¨le entraÃ®nÃ©
    â†“
[save_model()]
    â†“
ğŸ’¾ asthma_model.pkl (3-6 MB)
```

### 2. PrÃ©diction (main.py)

```
ğŸ“± App Flutter
    â†“ POST /api/predict
ğŸŒ Flask API
    â†“ request.get_json()
ğŸ“‹ data = {'symptoms': {...}, 'demographics': {...}, 'sensors': {...}}
    â†“ features = {merged}
ğŸ§  predictor.predict(features)
    â†“
[model.predict_proba()]
    â†“
ğŸ“Š probabilities = [0.265, 0.258, 0.477]
    â†“
[apply threshold]
    â†“
ğŸ¯ risk_level = 3 (Ã‰levÃ©)
    â†“
[generate_recommendations()]
    â†“
ğŸ’¡ recommendations = [...]
    â†“ jsonify()
ğŸŒ Response JSON
    â†“
ğŸ“± App Flutter (affichage)
```

---

## ğŸ“ Concepts ClÃ©s Ã  Retenir

### Random Forest
- **Ensemble de 151 arbres** qui votent
- Chaque arbre voit des donnÃ©es lÃ©gÃ¨rement diffÃ©rentes (bootstrap)
- PrÃ©diction finale = **vote majoritaire** ou **probabilitÃ©s moyennes**

### HyperparamÃ¨tres
- `n_estimators=151` : Nombre d'arbres (impair!)
- `max_depth=12` : Profondeur max
- `class_weight={..., 3:1.5}` : PrioritÃ© classe critique
- `n_jobs=-1` : ParallÃ©lisation

### Seuil Critique
- Si probabilitÃ©(Ã‰levÃ©) â‰¥ 65% â†’ **Force alerte**
- PrioritÃ© sÃ©curitÃ© mÃ©dicale
- RÃ©duit faux nÃ©gatifs de 87%

### Features Importantes
1. **RespiratoryRate** (29%) : FrÃ©quence respiratoire
2. **PM25** (25%) : Particules fines
3. **Nasal-Congestion** (8%) : Congestion nasale

### API Flask
- `/api/predict` : POST endpoint pour prÃ©dictions
- Format JSON : `{symptoms, demographics, sensors}`
- Retour : `{risk_level, risk_label, probabilities, recommendations}`

---

**ğŸ“š Documentation ComplÃ¨te** :
- [RANDOM_FOREST_EXPLICATIONS_COMPLETES.md](RANDOM_FOREST_EXPLICATIONS_COMPLETES.md)
- [RESULTATS_MODELE.md](RESULTATS_MODELE.md)
- [ARCHITECTURE_FINALE.md](ARCHITECTURE_FINALE.md)

**Date** : 19 janvier 2026
